import React from "react";
import { motion } from "framer-motion";

export default function Conclusion() {
  return (
    <div className="max-w-5xl mx-auto">
      <motion.h1
        className="text-4xl font-bold mb-6 text-primary"
        initial={{ opacity: 0, y: -10 }}
        animate={{ opacity: 1, y: 0 }}
      >
        Conclusion & Future Work
      </motion.h1>

      <p className="mb-4">
        This thesis demonstrates that <strong>Generative AI</strong> and
        <strong>Code Generation Agents</strong> can act as bridges between software and
        hardware, allowing robotic systems to be designed and controlled using natural
        language.
      </p>

      <p className="mb-4">
        The prototype robot autonomously ran code generated by an LLM, proving that AI
        can physically influence its environment — marking a step toward embodied
        intelligence.
      </p>

      <h2 className="text-2xl font-semibold mt-6 mb-2 text-accent">Key Takeaways</h2>
      <ul className="list-disc ml-6">
        <li>AI can autonomously generate, test, and run embedded control code.</li>
        <li>LLMs serve effectively as interpreters between human intent and machines.</li>
        <li>Self-identification of components remains an open research challenge.</li>
      </ul>

      <h2 className="text-2xl font-semibold mt-6 mb-2 text-accent">Future Directions</h2>
      <ul className="list-disc ml-6">
        <li>Develop complete hardware self-identification algorithms.</li>
        <li>Optimize LLMs for embedded deployment (quantized edge models).</li>
        <li>Expand the framework for multi-robot and industrial settings.</li>
      </ul>

      <p className="mt-6 italic text-gray-600">
        “Exploring the boundary between digital thought and physical action marks
        the beginning of truly intelligent systems.”
      </p>
    </div>
  );
}